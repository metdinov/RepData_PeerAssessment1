pbinom(35, size=3000000, prob=0.00001)
pbinom(35, size=3000000, prob=0.00001, lower.tail=FALSE)
pbinom(34, size=3000000, prob=0.00001, lower.tail=FALSE)
load(url("http://www.openintro.org/stat/data/kobe.RData"))
head(kobe)
kobe$basket[1:9]
kobe_streak <- calc_streak(kobe$basket)
barplot(table(kobe_streak))
sim_unfair_coin <- sample(outcomes, size = 100, replace = TRUE, prob = c(0.2,
0.8))
sim_unfair_coin <- sample(outcomes, size = 100, replace = TRUE, prob = c(0.2,                                                                     0.8))
sim_unfair_coin <- sample(outcomes, size = 100, replace = TRUE, prob = c(0.2, 0.8))
outcomes <- c("heads", "tails")
sample(outcomes, size = 1, replace = TRUE)
sim_fair_coin <- sample(outcomes, size = 100, replace = TRUE)
sim_unfair_coin <- sample(outcomes, size = 100, replace = TRUE, prob = c(0.2, 0.8))
table(sim_unfair_coin)
outcomes <- c("H", "M")
sim_basket <- sample(outcomes, size = 1, replace = TRUE)
sim_basket <- sample(outcomes, size = 133, replace=TRUE, prob= c(0.45, 0.55))
table(sim_basket)
sim_basket
calc_streak(sim_basket)
table(calc_streak(sim_basket))
simulation <- table(calc_streak(sim_basket))
boxplot(simulation)
barplot(simulation)
qnorm(0.9)
qnorm(0.05)
qnorm(0.95)
help
ls
2*pnorm(1.82366)
pnorm(1.82366)
pnorm(1.82366, lower.tail=TRUE)
1 - pnorm(1.82366)
pnorm(-1,8236658932714617169373549883991)
pnorm(1,8236658932714617169373549883991)
pnorm(-1.8236658932714617169373549883991)
pnorm(1.3920187724940273041334890097792)
2*(1-pnorm(1.3920187724940273041334890097792))
qnorm(0.9)
qnorm(0.95)
qnorm(0.025)
qnorm(0.05)
load(url("http://www.openintro.org/stat/data/ames.RData"))
area <- ames$Gr.Liv.Area
price <- ames$SalePrice
summary(area)
hist(area)
samp0 <- sample(area, 50)
samp1 <- sample(area, 50)
population <- ames$Gr.Liv.Area
samp <- sample(population, 60)
summary(samp)
qnorm(0.5)
qnorm(0.6)
qnorm(0.9)
qnorm(1)
qnorm(0.4)
pnorm(0.5)
pnorm(0)
qnorm(0.5)
dnorm(0)
dnorm(0.5)
pnorm(c(-1.33,0))
nums <- c(35, 38, 40, 41, 38, 45, 42)
mean(nums)
sd(nums)
qnorm(0)
qnorm(0.5)
pnorm(0.5)
pnorm(0)
qnorm(0.99)
qnorm(0.99, mean = 33, sd = 1.2)
load("E:/Courses/The Analytics Edge/Week 2/.RData")
rm(PresTest1)
PredTest1
RMSE <- sqrt(sum((FluTest$ILI - PredTest1)^2)/nrow(PredTest1))
RMSE
FluTest$ILI
PredTest1
sum((FluTest$ILI - PredTest1)^2)
nrow(PredTest1)
RMSE <- sqrt(sum((FluTest$ILI - PredTest1)^2)/nrow(FluTest))
RMSE
install.packages("zoo")
library(zoo)
ILILag2 = lag(zoo(FluTrain$ILI), -2, na.pad=TRUE)
FluTrain$ILILag2 = coredata(ILILag2)
summary(ILILag2)
plot(log(FluTrain$ILILag2), log(FluTrain$ILI))
FluTrend2 <- lm(log(ILI) ~ Queries + log(ILILag2), data= FluTrain)
summary(FluTrend2)
summary(FluTrend1)
ILILag2Test = lag(zoo(FluTest$ILI), -2, na.pad=TRUE)
FluTest$ILILag2 = coredata(ILILag2Test)
summary(FluTest$ILILag2)
FluTest$ILILag2[0]
FluTest$ILILag2[1]
FluTest$ILILag2[2]
FluTest$ILILag2[3]
FluTest$ILI[0]
FluTest$ILI[1]
FluTest$ILILag2[1] = FluTrain$ILI[416]
FluTrain$ILI[416]
FluTrain$ILI[417]
FluTrain$ILI[418]
FluTest$ILILag2[2] = FluTrain$ILI[417]
predict(FluTrend2, FluTest)
RMSE <- sqrt(sum((FluTest$ILI - exp(predict(FluTrend2, FluTest)))^2)/nrow(FluTest))
RMSE
?arima
e
E
exp(1)
log(1)
10.6513/0.0055
exp(-6 + .)
exp(-6 + 0.05*40 + 3.5)/(1 + exp(-6 + 0.05*40 + 3.5))
(6-3.5)/0.05
?cv.glmnet()
require(glmnet)
install.packages(glmnet)
install.packages("glmnet")
?cv.glmnet()
glmnet
glmnet()
require('glmnet')
?cv.glmnet()
SE = 4.65/sqrt(40)
SE
pnorm(0)
pnorm(-1)
zscore = (9.51 - 10)/SE
zscore
pnorm(zscore)
calcium <- c(-5, -4, -3, -2, 1, 7, 10, 11, 17, 18)
median(calcium)
placebo <- c(-11, -5, -3, -3, -1, -1, -1, 2, 3, 5, 12)
median(placebo)
join <- c(calcium, placebo)
join
mean(join)
meadian(join)
median(join)
for(1:100) {}
for(i in 1:100) { test1 = sample(21, join)}
for(i in 1:100) {}
meds = 0
for(i in 1:100) { test1 = sample(join); calci = test1[1:10]; plac = test1[11:21]; meds[i] = median(calci) - median(plac)}
meds
mean(meds)
mean(meds >5 | meds < -5)
qnorm(0.1)
qnorm(0.05)
qnorm(0.025)
(qnorm(0.1)*18/4)^2
qnorm(0.842)
qnorm(0.80)
qnorm(0.90)
pnorm(qnorm(0.90) * 0.65)
pnorm(qnorm(0.40) * 0.65)
plot(rand(1))
randu(100)
pnorm(qnorm(0.90) * 0.65)
pnorm(qnorm(0.40) * 0.65)
-1.5+3*1-0.5*5
exp(-1)
0.3678794/(1+0.3678794)
load("E:/Courses/The Analytics Edge/Week 3/Week3_ModelingExpert.R")
ls
install.package('ISLR')
??install
library(ISLR)
install.packages("zoo")
install.packages("ISLR")
install.packages("ROCR")
install.packages("ggplot2")
x <- runif(100)
y <- runif(100)
plot(y ~ x)
legend(c(10,10), 'Hola')
legend('Hola')
legend(2,3, 'Hola')
legend(2,3, title = 'Hola')
legend(2,3, c('epa', 'es mio'), title = 'Hola')
legend(2,.4, c('epa', 'es mio'), title = 'Hola')
demo(plotmath)
x <- runif(100)
y <- runif(100)
plot(y ~ x, text = expression(x ^ 2))
plot(y ~ x, title = expression(x ^ 2))
warnings()
plot(y ~ x, xlab = expression(x ^ 2))
x <- runif(100)
y <- x^2
plot(y ~ x, ylab = expression(x ^ 2))
pt(2.485, df = 21)
2 * pt(2.485, df = 21, lower.tail=FALSE)
2 * pt(2.485, df = 25, lower.tail=FALSE)
0.0025
qt(0.0025, df = 24)
qt(0.025, df = 24)
qt(0.05, df = 24)
load(url("http://bit.ly/dasi_nc"))
summary(nc)
head(nc)
gained_clean = na.omit(nc$gained)
n = length(gained_clean)
boot_means = rep(NA, 100)
for(i in 1:100){
boot_sample = sample(gained_clean, n, replace = TRUE)
boot_means[i] = mean(boot_sample)
}
hist(boot_means)
source("http://bit.ly/dasi_inference")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.9, est = "mean",
boot_method = "perc")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.95, est = "mean",
boot_method = "perc")
levels(nc$habit)
boxplot(nc$weight ~ nc$habit)
range
range(nc$weight)
inference(nc$weight, type = "ci", method = "simulation", conflevel = 0.95, est = "mean",
boot_method = "perc")
by(nc$weight, nc$habit, mean)
inference(y = nc$weight, x = nc$habit, est = "mean", type = "ht", null = 0,
alternative = "twosided", method = "theoretical")
inference(y = nc$weight, x = nc$habit, est = "mean", type = "ci", null = 0,
alternative = "twosided", method = "theoretical", order = c("smoker","nonsmoker"))
str(nc)
table(nc$mage, nc$mature)
inference(y = gss$wordsum, x = gss$class, est = "mean", type = "ht",
alternative = "greater", method = "theoretical")
load(url("http://bit.ly/dasi_gss_ws_cl"))
inference(y = gss$wordsum, x = gss$class, est = "mean", type = "ht",
alternative = "greater", method = "theoretical")
0.36*0.64*2
-(0.36*log(0.36) + 0.64*log(0.64))
for(j in 1:10) {
trainMatrix = matrix(rnorm(1000), 100, 10)
trainMatrix[1:50,1:5] = trainMatrix[1:50,1:5] + 1
traindf <- data.frame(trainMatrix)
traindf$y = 0
for (i in 1:100) {
if(i <= 50) {
traindf[i,]$y = 0
} else {
traindf[i,]$y = 1
}
}
svmfit = svm(formula = y ~ ., data = traindf, kernel = 'radial')
2
}
install.package(e1071)
install.packages(e1071)
install.packages('e1071')
for(j in 1:10) {
trainMatrix = matrix(rnorm(1000), 100, 10)
trainMatrix[1:50,1:5] = trainMatrix[1:50,1:5] + 1
traindf <- data.frame(trainMatrix)
traindf$y = 0
for (i in 1:100) {
if(i <= 50) {
traindf[i,]$y = 0
} else {
traindf[i,]$y = 1
}
}
}
svmfit = svm(formula = y ~ ., data = traindf, kernel = 'radial')
library(e1017)
library('e1017')
install.packages('knitr')
library(e1071)
svmfit = svm(formula = y ~ ., data = traindf, kernel = 'radial')
x <- runif(100)
plot(x)
hist(x)
mean(x)
median(x)
x <- c(x, 10000000000)
mean(x)
median(x)
x <- runif(1000)
hist(x)
plot(x)
hist(x)
x <- c(x, 1000000)
tail(x)
median9x
median(x)
exit
qnorm(0.9)
qnorm(0.95)
qnorm(0.75)
pnorm(1.644854)
qnorm(0.8)
qnorm(0.85)
qnorm(0.84)
qnorm(0.845)
qnorm(0.844)
qnorm(0.843)
qnorm(0.842)
qnorm(0.841)
qnorm(0.8415)
qnorm(-0.125)
qnorm(0.125)
pnorm(-0.125)
pnorm(-0.598)
x <- runif(1000)
plot(x)
hist(x)
mean(x)
median(x)
x <- c(x, 1000000)
median(x)
mean(x)
yes2012 <- 493/1037
yes2013 <- 596/1028
pooledYes <- (493 + 596)/(1037+1028)
SE <- sqrt(pooledYes/1037 + pooledYes/1028)
SE
SE <- sqrt(pooledYes*(1-pooledYes)/1037 + pooledYes*(1-pooledYes)/1028)
SE
source("http://bit.ly/dasi_inference")
pop = c(10, 4, 12, 15, 20, 5)
vec=c(1,2)
pop.sd=function(x)(sqrt(var(x)*(length(x)-1)/length(x)))
pop.sd(vec) ##as compared to
sd(vec)
pop.sd(pop)
mean(pop)
sum(pop)/6
pop.sd(pop)/11
?knitr
??knitr
install.packages('kernsmooth')
install.packages('KernSmooth')
library(KernSmooth)
load(url("http://www.openintro.org/stat/data/mlb11.RData"))
pf(4.1081, 2, 828, lower.tail= FALSE)
pf(3.4725, 2, 828, lower.tail= FALSE)
C1 = c(2, 2, -6, -6)
C1^2
C1^2 - mean(C1)
sum(C1^2 - mean(C1))
C2 = c(-4, -4, 2)
sum(C2^2 - mean(C2))
42/3
88/4
sum(C1^ - mean(C1)^2)
sum(C1^ - mean(C1))^2
sum(C1 - mean(C1))^2
C1
mean(C1)
sum((C1 - mean(C1))^2)
sum((C2 - mean(C2))^2)
C3 = c(2, 2, 2)
sum((C3 - mean(C3))^2)
C4 = c(-6, -6, -4, -4)
sum((C4 - mean(C4))^2)
?windows
?dev.copy2pdf
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
1+2+3+4
10/4
0.1+0.2*2+3.0*0.3+4.0*0.4
dnorm(70, mean = 80, sd = 10)
dnorm(80, mean = 80, sd = 10)
pnorm(80, mean = 80, sd = 10)
pnorm(70, mean = 80, sd = 10)
qnorm(70, mean = 80, sd = 10)
pnorm(70, mean = 80, sd = 10)
qnorm(0.95, mean = 1100, sd = 75)
qnorm(0.95)
pbinom(3, size = 5, prob=0.5, lower.tail=FALSE)
1100+1.644854*7.5
qnorm(0.5, mean = 1100, sd= 75)
1100+1.96*7.5
qnorm(0.95, mean = 1100, sd= 75)
pnorm(1223.364, mean = 1100, sd= 75)
pnorm(1.96)
ppois(10, lambda=5 * 3)
combn(9,3)
choose(9, 3)
library(lattice)
xyplot
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
p
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(ggplot2)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies, panel = panel.loess)
activityData <- fread("activity.csv", sep = ",")
activityData <- activityData[, date := as.Date(date)]
setkey(activityData, date, interval)
setwd("e:/Courses/repdata-002/Projects/RepData_PeerAssessment1/")
activityData <- fread("activity.csv", sep = ",")
activityData <- activityData[, date := as.Date(date)]
setkey(activityData, date, interval)
library(data.table)
library(ggplot2)
activityData <- fread("activity.csv", sep = ",")
activityData <- activityData[, date := as.Date(date)]
setkey(activityData, date, interval)
library(Amelia)
imputed <- amelia(activityData, m = 5, ts = "date", ords = "steps", p2s = 0)
table(imputed$imputations[[3]]$steps)
table(activityData$steps)
imputedTotalSteps <- imputed[, sum(steps), by = date]
setnames(imputedTotalSteps, c("date", "total.steps"))
imputed.hist <- ggplot(imputedTotalSteps, aes(x = date, y = total.steps)) + theme_bw()
imputed.hist <- imputed.hist + geom_histogram(stat = "identity", fill = "dark blue", alpha = 0.7)
imputed.hist <- imputed.hist + xlab("Date") + ylab("Total Number of Steps")
print(imputed.hist)
imputed
imputed <- imputed$imputations[[1]]
imputedTotalSteps <- imputed[, sum(steps), by = date]
setnames(imputedTotalSteps, c("date", "total.steps"))
imputed.hist <- ggplot(imputedTotalSteps, aes(x = date, y = total.steps)) + theme_bw()
imputed.hist <- imputed.hist + geom_histogram(stat = "identity", fill = "dark blue", alpha = 0.7)
imputed.hist <- imputed.hist + xlab("Date") + ylab("Total Number of Steps")
print(imputed.hist)
imputed
imputed[steps <0]
imputed[steps <1]
imputed[steps > 806]
imputed.hist + labs(title = "Total Number of Steps for the Imputed Data Set")
meanStepsInterval <- activityData[, mean(steps, na.rm = TRUE), by = interval] # Get the mean steps per interval
setnames(meanStepsInterval, c("interval", "mean.steps"))
time.series <- ggplot(meanStepsInterval, aes(x = interval, y = mean.steps)) + theme_bw()
time.series <- time.series + geom_line(color = "dark blue") + labs(title = "Average Number of Steps per Interval", x = "Interval", y = "Average Number of Steps")
print(time.series)
Sys.setlocale("LC_TIME", "English_United States.1252")
weekdays("2014-05-17")
weekdays(as.Date("2014-05-17"))
imputed[, day := weekdays(date)]
tables
tables()
teste <- imputed
teste[, lolo := steps * 2, verbose = FALSE]
test
teste
x = c(2, 3)
2 in x
2 %in% x
4 %in% x
daysOfWeek <- c("weekend", rep("weekday", 5), "weekend")
"weekday" %in% daysOfWeek
"weekda2y" %in% daysOfWeek
imputed[, day := ifelse(day %in% weekendDays, "weekend", "weekday")]
weekendDays <- c("Sunday", "Saturday")
imputed[, day := ifelse(day %in% weekendDays, "weekend", "weekday")]
imputed
table(imputed$day)
table(imputed[by = date]$day)
4608/12960
2/5
class(imputed$day)
teste
imputed$day <- as.factor(imputed$day)
imputed$date
imputed$day
imputedTotalSteps
imputedTotalSteps[, day := weekdays(date), verbose = FALSE]
weekendDays <- c("Sunday", "Saturday")
imputedTotalSteps[, day := ifelse(day %in% weekendDays, "weekend", "weekday")]
imputedTotalSteps$day <- as.factor(imputedTotalSteps$day)
imputedTotalSteps[, mean.steps := mean(steps), by = interval]
imputedTotalSteps
imputedMeanSteps <- imputed[, mean(steps), by = interval]
imputedMeanSteps
imputedMeanSteps <- imputed[, mean(steps), by = list("interval", "day")]
imputedMeanSteps <- imputed[, mean(steps), by = "interval,day"]
imputedMeanSteps
imputedMeanSteps[interval == 0]
setnames(imputedMeanSteps, c("interval", "day", "mean.steps"))
imputedMeanSteps[interval == 0]
ts.weekdays <- ggplot(imputed, aes(x = interval, y = mean.steps, color = day)) + geom_line() + theme_bw()
ts.weekdays <- ts.weekdays + facet_wrap(~ day, nrow = 2)
ts.weekdays <- ts.weekdays + labs(title = "Average Number of Steps per Interval", x = "Interval", y = "Number of Steps")
print(ts.weekdays)
ts.weekdays <- ggplot(imputedMeanSteps, aes(x = interval, y = mean.steps, color = day)) + geom_line() + theme_bw()
ts.weekdays <- ts.weekdays + facet_wrap(~ day, nrow = 2)
ts.weekdays <- ts.weekdays + labs(title = "Average Number of Steps per Interval", x = "Interval", y = "Number of Steps")
print(ts.weekdays)
